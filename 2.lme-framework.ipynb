{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a6b3fd6-1753-45e7-a920-fccf68cbdcac",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# The Mixed-effects Framework\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874b35db",
   "metadata": {},
   "source": [
    "## The Hierarchical Perspective\n",
    "\n",
    "... These are sometimes called *hierarchical* or *multilevel* models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca08be4",
   "metadata": {},
   "source": [
    "### Fitting a Model to a Single Subject\n",
    "To begin with, let us imagine that we only have the data for a *single subject*. What kind of model could we fit?\n",
    "\n",
    "... So, notice that if we allow the model to freely estimate the effect of `condition`, it will fit the data *perfectly* and there will be no error. This tells us that we cannot let this effect be unique to each subject because the data does not support it. So, in this instance, the data constrains us to the model\n",
    "\n",
    "...\n",
    "\n",
    "where $\\alpha_{j}$ is a *constant* across all subjects, rather than being unique to subject $i$. So this is our final model, if we *only* had the data for this one subject. \n",
    "\n",
    "Now, let us imagine that we ran the experiment *again* and collected a different subject. What do we think would change? Well, certainly the term $\\mu_{i}$. We have different data now and so the grand mean is almost certainly going to change. What else? Well, the errors will also change, as we would expect. What would not change would be $\\alpha_{j}$, because we have assumed that this is *constant* across subjects. So, we have $\\mu_{i}$ that wil differ with each new subject and $\\eta_{ij}$ that will differ with each observation within each subject.\n",
    "\n",
    "What does this mean for both $\\mu_{i}$ and $\\eta_{ij}$? Well, what do we call a variable that changes every time we observe it? A *random variable*. So, both $\\mu_{i}$ and $\\eta_{ij}$ are *random variables*. This means that they *both* have some underlying distribution that they are drawn from. As we know, the $\\eta_{ij}$ are *errors* and thus reflect *deflections* around the expected value. As such, their distribution is the same as it always was \n",
    "\n",
    "$$\n",
    "\\eta_{ij} \\sim \\mathcal{N}\\left(0, \\sigma^{2}_{w}\\right).\n",
    "$$\n",
    "\n",
    "But what about the $\\mu_{i}$? Well, as written above, these are *means* for each subject, so their expected value will not be 0. Instead, it will be whatever the *population grand mean* happens to be. Their variance will then represent the variability of the subject means, which we will call $\\sigma^{2}_{b}$. As such\n",
    "\n",
    "$$\n",
    "\\mu_{i} \\sim \\mathcal{N}\\left(\\mu, \\sigma^{2}_{b}\\right).\n",
    "$$\n",
    "\n",
    "So our full model is now\n",
    "\n",
    "$$\n",
    "\\begin{alignat*}{1}\n",
    "    y_{ij}        &=    \\mu_{i} + \\alpha_{j} + \\eta_{ij}           \\\\\n",
    "    \\mu_{i}       &\\sim \\mathcal{N}\\left(\\mu,\\sigma^{2}_{b}\\right) \\\\\n",
    "    \\epsilon_{ij} &\\sim \\mathcal{N}\\left(0,\\sigma^{2}_{w}\\right)   \\\\\n",
    "\\end{alignat*}\n",
    "$$\n",
    "\n",
    "For each subject we observe, we have a subject-specific intercept $\\mu_{i}$, a constant effect of condition $j$ (as constrained by the data) and an observation-specific error $\\eta_{ij}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b096bf3",
   "metadata": {},
   "source": [
    "### Fitting Individual Linear Models in `R`\n",
    "Each time we do this, we will collect the estimates of $\\mu_{i}$ and $\\epsilon_{ij}$, just to demonstrate that these are the elements that truly *do* change with each new subject. We will then show the distribution of these at the end to illustrate that these terms are indeed *random variables*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f722f66",
   "metadata": {},
   "source": [
    "### The Hierarchical Model\n",
    "\n",
    "... Given the model above, we can start to play around with how it is written. This will lead us directly to the *multilevel* way of viewing these models.\n",
    "\n",
    "Remembering back to how we can specify a linear model in terms of either a distribution on the *outcome variable* or a distribution on the *errors*, we can do exactly the same thing with the $\\mu_{i}$ terms. At present, this is expressed as a distribution on the outcome variable (all the different observed values of $\\mu_{i}$). But we can separate this out like so\n",
    "\n",
    "$$\n",
    "\\begin{alignat*}{1}\n",
    "    y_{ij}    &= \\mu_{i} + \\alpha_{j} + \\eta_{ij}        \\\\\n",
    "    \\mu_{i}   &= \\mu + S_{i}                              \\\\\n",
    "    S_{i}     &\\sim \\mathcal{N}\\left(0,\\sigma^{2}_{b}\\right) \\\\\n",
    "    \\eta_{ij} &\\sim \\mathcal{N}\\left(0,\\sigma^{2}_{w}\\right) \\\\\n",
    "\\end{alignat*}\n",
    "$$\n",
    "\n",
    "So we have written $\\mu_{i}$ in terms of its *mean function* and a new error term $S_{i}$. This is *exactly* the multilevel/hierarchical perspective. We now have *two levels* of variation that we are modelling. Level 1 expresses the model for an individual subject and Level 2 expresses the model for the *group* of subjects. We could write this like so\n",
    "\n",
    "$$\n",
    "\\begin{alignat*}{2}\n",
    "\\text{Level 1 (Subject)}\\quad&\n",
    "\\begin{cases}\n",
    "    y_{ij}    = \\mu_{i} + \\alpha_{j} + \\eta_{ij}            \\\\\n",
    "    \\eta_{ij} \\sim \\mathcal{N}\\left(0,\\sigma^{2}_{w}\\right) \\\\\n",
    "    \n",
    "\\end{cases} \\\\\n",
    "\\text{Level 2 (Group)}\\quad&\n",
    "\\begin{cases}\n",
    "    \\mu_{i} = \\mu + S_{i}                                 \\\\\n",
    "    S_{i}   \\sim \\mathcal{N}\\left(0,\\sigma^{2}_{b}\\right) \\\\\n",
    "    \\end{cases}\n",
    "\\end{alignat*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0daeed9",
   "metadata": {},
   "source": [
    "## From Hierarchy to Mixed-effects\n",
    "... So, the key here is recognising that we can collapse the two equations\n",
    "\n",
    "$$\n",
    "\\begin{alignat*}{1}\n",
    "    y_{ij}    &= \\mu_{i} + \\alpha_{j} + \\eta_{ij}  \\\\\n",
    "    \\mu_{i}   &= \\mu + S_{i}                       \\\\\n",
    "\\end{alignat*}\n",
    "$$\n",
    "\n",
    "After all, we can see exactly what $\\mu_{i}$ is equal to. So let us replace $\\mu_{i}$ in the first equation with the equality in the second equation. If we do so, we get\n",
    "\n",
    "$$\n",
    "\\begin{alignat*}{1}\n",
    "    y_{ij} &= (\\mu + S_{i}) + \\alpha_{j} + \\eta_{ij} \\\\\n",
    "           &= \\mu + \\alpha_{j} + S_{i} + \\eta_{ij}\n",
    "\\end{alignat*}\n",
    "$$\n",
    "\n",
    "with\n",
    "\n",
    "$$\n",
    "\\begin{alignat*}{1}\n",
    "    S_{i}     &\\sim \\mathcal{N}\\left(0,\\sigma^{2}_{b}\\right) \\\\\n",
    "    \\eta_{ij} &\\sim \\mathcal{N}\\left(0,\\sigma^{2}_{w}\\right) \\\\\n",
    "\\end{alignat*}\n",
    "$$\n",
    "\n",
    "This is *exactly the partitioned error model we saw last week*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c92ba8",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
