
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Mixed-effects Models in R &#8212; An Introduction to Linear Mixed-effects Models</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="_static/test.css?v=a80109f0" />
    <link rel="stylesheet" type="text/css" href="_static/sphericity_3d_files/rglwidgetClass-1.3.18/rgl.css?v=57907efa" />
    <link rel="stylesheet" type="text/css" href="_static/sphericity_3d_files/htmltools-fill-0.5.8.1/fill.css?v=971cc1da" />
  
  <!-- So that users can add custom icons -->
  <script src="_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '5.mixed-R';</script>
    <script src="_static/sphericity_3d_files/rglwidgetClass-1.3.18/textures.src.js?v=9482728f"></script>
    <script src="_static/sphericity_3d_files/rglwidgetClass-1.3.18/shadersrc.src.js?v=6ce05c17"></script>
    <script src="_static/sphericity_3d_files/rglwidgetClass-1.3.18/buffer.src.js?v=1efca185"></script>
    <script src="_static/sphericity_3d_files/rglwidgetClass-1.3.18/mouse.src.js?v=96f0b970"></script>
    <script src="_static/sphericity_3d_files/rglwidgetClass-1.3.18/projection.src.js?v=98871b91"></script>
    <script src="_static/sphericity_3d_files/rglwidgetClass-1.3.18/axes.src.js?v=3250d244"></script>
    <script src="_static/sphericity_3d_files/rglwidgetClass-1.3.18/rglTimer.src.js?v=ac1c3151"></script>
    <script src="_static/sphericity_3d_files/rglwidgetClass-1.3.18/pretty.src.js?v=4f2cffba"></script>
    <script src="_static/sphericity_3d_files/rglwidgetClass-1.3.18/shaders.src.js?v=bbbdf37d"></script>
    <script src="_static/sphericity_3d_files/rglwidgetClass-1.3.18/animation.src.js?v=74f9b9e8"></script>
    <script src="_static/sphericity_3d_files/rglwidgetClass-1.3.18/pieces.src.js?v=280fd571"></script>
    <script src="_static/sphericity_3d_files/rglwidgetClass-1.3.18/selection.src.js?v=5b47ed7d"></script>
    <script src="_static/sphericity_3d_files/rglwidgetClass-1.3.18/init.src.js?v=f5bdcbbb"></script>
    <script src="_static/sphericity_3d_files/rglwidgetClass-1.3.18/subscenes.src.js?v=42cb429d"></script>
    <script src="_static/sphericity_3d_files/rglwidgetClass-1.3.18/controls.src.js?v=4b3dbe6f"></script>
    <script src="_static/sphericity_3d_files/rglwidgetClass-1.3.18/draw.src.js?v=49d9cbaa"></script>
    <script src="_static/sphericity_3d_files/rglwidgetClass-1.3.18/utils.src.js?v=56efe719"></script>
    <script src="_static/sphericity_3d_files/rglwidgetClass-1.3.18/rglClass.src.js?v=9e593197"></script>
    <script src="_static/sphericity_3d_files/rglWebGL-binding-1.3.18/rglWebGL.js?v=8cd6f6d7"></script>
    <script src="_static/sphericity_3d_files/htmlwidgets-1.6.4/htmlwidgets.js?v=175713be"></script>
    <script src="_static/sphericity_3d_files/CanvasMatrix4-1.3.18/CanvasMatrix.src.js?v=5a2d04be"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Summary" href="summary.html" />
    <link rel="prev" title="From Multilevel to Mixed-effects" href="4.multilevel-to-mixed.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="0.intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="An Introduction to Linear Mixed-effects Models - Home"/>
    <img src="_static/logo.png" class="logo__image only-dark pst-js-only" alt="An Introduction to Linear Mixed-effects Models - Home"/>
  
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="0.intro.html">
                    Introduction
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="1.intro-mixed.html">Introduction to Mixed-effects Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="2.multilevel-framework.html">The Multilevel Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="3.multilevel-simulation.html">Simulating a Multilevel Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="4.multilevel-to-mixed.html">From Multilevel to Mixed-effects</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Mixed-effects Models in <code class="docutils literal notranslate"><span class="pre">R</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="summary.html">Summary</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/PCHN63112-Mixed-Models/mixed-effects-intro" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/PCHN63112-Mixed-Models/mixed-effects-intro/issues/new?title=Issue%20on%20page%20%2F5.mixed-R.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/5.mixed-R.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Mixed-effects Models in R</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fitting-mixed-effects-models-with-nlme">Fitting Mixed-effects Models with <code class="docutils literal notranslate"><span class="pre">nlme</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#specifying-random-effects">Specifying Random-effects</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exploring-the-lme-output">Exploring the <code class="docutils literal notranslate"><span class="pre">lme()</span></code> Output</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#inference-in-mixed-effects-models">Inference in Mixed-effects Models</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-implied-marginal-model">The Implied Marginal Model</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-marginal-covariance-structure">The Marginal Covariance Structure</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#inference-using-nlme">Inference Using <code class="docutils literal notranslate"><span class="pre">nlme</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#anova-tables-and-follow-up-tests">ANOVA Tables and Follow-up Tests</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#omnibus-tests-from-anova">Omnibus Tests From <code class="docutils literal notranslate"><span class="pre">Anova()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#follow-up-tests-from-emmeans">Follow-up Tests From <code class="docutils literal notranslate"><span class="pre">emmeans()</span></code></a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="mixed-effects-models-in-r">
<h1>Mixed-effects Models in <code class="docutils literal notranslate"><span class="pre">R</span></code><a class="headerlink" href="#mixed-effects-models-in-r" title="Link to this heading">#</a></h1>
<p>As the final part of this lesson, we turn to the process of fitting LME models using <code class="docutils literal notranslate"><span class="pre">R</span></code>, as well as options around inference. These examples will all be fairly basic, but we will see more variety in the workshop this week. In addition, our focus will be on the <code class="docutils literal notranslate"><span class="pre">nlme</span></code> package to keep things simple. In reality, there are <em>two</em> <code class="docutils literal notranslate"><span class="pre">R</span></code> packages that are used frequently in practice: <code class="docutils literal notranslate"><span class="pre">nlme</span></code> and <code class="docutils literal notranslate"><span class="pre">lme4</span></code>. Both have their advantages and disadvantages, however, they are so similar that knowing one would easily allow you to use the other. For our purpose, the advantages of <code class="docutils literal notranslate"><span class="pre">lme4</span></code> are few at present and so we stick with <code class="docutils literal notranslate"><span class="pre">nlme</span></code> to reduce confusion.</p>
<section id="fitting-mixed-effects-models-with-nlme">
<h2>Fitting Mixed-effects Models with <code class="docutils literal notranslate"><span class="pre">nlme</span></code><a class="headerlink" href="#fitting-mixed-effects-models-with-nlme" title="Link to this heading">#</a></h2>
<p>To fit an LME model using <code class="docutils literal notranslate"><span class="pre">nlme</span></code>, we use the <code class="docutils literal notranslate"><span class="pre">lme()</span></code> function, which has a syntax very similar to the <code class="docutils literal notranslate"><span class="pre">gls()</span></code> function. To understand how to use this, we will return to the long-formatted <code class="docutils literal notranslate"><span class="pre">anxiety</span></code> data from <code class="docutils literal notranslate"><span class="pre">datarium</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">head</span><span class="p">(</span><span class="n">anxiety.long</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  id time score
1 31   t1  14.6
2 31   t2  13.0
3 31   t3  11.7
4 32   t1  15.0
5 32   t2  13.0
6 32   t3  11.9
</pre></div>
</div>
</div>
</div>
<p>Our multilevel model for these data was specified earlier as</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{alignat*}{2}
    y_{ij}    &amp;= \mu_{i} + \alpha_{j} + \eta_{ij} &amp;\quad\text{Level 1} \\
    \mu_{i}   &amp;= \mu + \xi_{i}                    &amp;\quad\text{Level 2} \\
\end{alignat*}
\end{split}\]</div>
<p>which we can collapse to a single level by replacing <span class="math notranslate nohighlight">\(\mu_{i}\)</span> with <span class="math notranslate nohighlight">\(\mu + \xi_{i}\)</span> at Level 1. This gives the LME model</p>
<div class="math notranslate nohighlight">
\[
y_{ij} = \mu + \alpha_{j} + \xi_{i} + \eta_{ij},
\]</div>
<p>where we have <em>two</em> fixed-effects of <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\alpha_{j}\)</span>, and <em>two</em> random-effects of <span class="math notranslate nohighlight">\(\xi_{i}\)</span> and <span class="math notranslate nohighlight">\(\eta_{ij}\)</span>. To fit this model using <code class="docutils literal notranslate"><span class="pre">lme()</span></code> we use</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">library</span><span class="p">(</span><span class="n">nlme</span><span class="p">)</span>
<span class="n">lme.mod</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">lme</span><span class="p">(</span><span class="n">score</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">time</span><span class="p">,</span><span class="w"> </span><span class="n">random</span><span class="o">=</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="m">1</span><span class="o">|</span><span class="n">id</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="o">=</span><span class="n">anxiety.long</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<section id="specifying-random-effects">
<h3>Specifying Random-effects<a class="headerlink" href="#specifying-random-effects" title="Link to this heading">#</a></h3>
<p>As we can see above, the newest element of the <code class="docutils literal notranslate"><span class="pre">lme()</span></code> function is the <code class="docutils literal notranslate"><span class="pre">random=</span></code> argument. This uses a syntax very similar to what we have seen before when using <code class="docutils literal notranslate"><span class="pre">correlation=</span></code> and <code class="docutils literal notranslate"><span class="pre">weights=</span></code> with <code class="docutils literal notranslate"><span class="pre">gls()</span></code>. However, we need to think about this a little differently because we are not defining how we want a particular covariance structure to apply to the data. Instead, we are giving the <em>structure</em> of the random effects.</p>
<p>We can think of this as simply a direct implementation of the LME equation above. We have</p>
<div class="math notranslate nohighlight">
\[
y_{ij} = \overbrace{\mu + \alpha_{j}}^{\text{fixed}} + \overbrace{\xi_{i} + \eta_{ij}}^{\text{random}},
\]</div>
<p>so the <em>fixed-effects</em> part just appears in the model equation as <code class="docutils literal notranslate"><span class="pre">score</span> <span class="pre">~</span> <span class="pre">time</span></code>. The <em>random-effects</em> part consists of <span class="math notranslate nohighlight">\(\xi_{i} + \eta_{ij}\)</span>, but we do not need to specify <span class="math notranslate nohighlight">\(\eta_{ij}\)</span> because that is the residual error term that is <em>always</em> included in a linear model. We know this already from <code class="docutils literal notranslate"><span class="pre">lm()</span></code> as we never have to ask for residuals, they are always there. So, the only thing that differentiates the model above from something we could fit with <code class="docutils literal notranslate"><span class="pre">lm()</span></code> is the term <span class="math notranslate nohighlight">\(\xi_{i}\)</span>. This is <em>precisely</em> what we specify using the <code class="docutils literal notranslate"><span class="pre">random=</span></code> argument.</p>
<p>So what is <span class="math notranslate nohighlight">\(\xi_{i}\)</span>? Well, if we look at its index, it is a value that changes with <em>each subject</em>. It is therefore <em>constant</em> within a subject, but different between subjects. So how do we specify a value that is only constant <em>within</em> each subject? Well, we represent it as a constant using a <code class="docutils literal notranslate"><span class="pre">1</span></code> but make it <em>conditional</em> on the subject by using <code class="docutils literal notranslate"><span class="pre">|id</span></code>. So <code class="docutils literal notranslate"><span class="pre">1|id</span></code> can be read as <em>a constant per-subject</em>.</p>
<div class="tip admonition">
<p class="admonition-title">Multilevel Conceptualisation</p>
<p>Alternatively, we can built the <code class="docutils literal notranslate"><span class="pre">lme()</span></code> syntax from the multilevel conceptualisation. We can then think of the <code class="docutils literal notranslate"><span class="pre">random=</span></code> argument as describing elements of the model that we fit to each individual subject. We will use some pseudo-code below to get the idea across, just be aware that most of this is not valid <code class="docutils literal notranslate"><span class="pre">lme()</span></code> syntax (but the ideas are hopefully clear). As described earlier, when we have <em>no replications</em> within each level of the repeated measures, the best we can do with the data from <em>one</em> subject is fit a constant. So our model for one subject would be something like</p>
<p><code class="docutils literal notranslate"><span class="pre">score[id</span> <span class="pre">==</span> <span class="pre">1]</span> <span class="pre">~</span> <span class="pre">1</span></code></p>
<p>If we wanted this to work for <em>all</em> subjects, we would need to indicate that we want a <em>different</em> constant for each subject, which would give something like</p>
<p><code class="docutils literal notranslate"><span class="pre">score</span> <span class="pre">~</span> <span class="pre">1|id</span></code></p>
<p>which we can read as “fit a constant <em>separately</em> for each level of <code class="docutils literal notranslate"><span class="pre">id</span></code>”.</p>
<p>Once we have multiple subjects, we have the option of estimating values by pooling data <em>across</em> subjects. So, with multiple subjects, we can add a fixed-effect of <code class="docutils literal notranslate"><span class="pre">time</span></code>. Using our current pseudo-code, this would give</p>
<p><code class="docutils literal notranslate"><span class="pre">score</span> <span class="pre">~</span> <span class="pre">1|id</span> <span class="pre">+</span> <span class="pre">time</span></code>.</p>
<p>However, this is <em>not</em> how <code class="docutils literal notranslate"><span class="pre">lme()</span></code> works. Instead, in order to clearly differentiate the random-effects from the fixed-effects, <code class="docutils literal notranslate"><span class="pre">lme()</span></code> requires that we move anything random out of the model equation and put it in a separate argument. So this gives the final <em>real</em> specification of</p>
<p><code class="docutils literal notranslate"><span class="pre">lme(score</span> <span class="pre">~</span> <span class="pre">time,</span> <span class="pre">random=</span> <span class="pre">~</span> <span class="pre">1|id)</span></code></p>
</div>
</section>
<section id="exploring-the-lme-output">
<h3>Exploring the <code class="docutils literal notranslate"><span class="pre">lme()</span></code> Output<a class="headerlink" href="#exploring-the-lme-output" title="Link to this heading">#</a></h3>
<p>Before we get into the hairy topic of <em>inference</em>, let us explore the model we have just fit. We can print the estimates and other details by calling</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">print</span><span class="p">(</span><span class="n">lme.mod</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Linear mixed-effects model fit by REML
  Data: anxiety.long 
  Log-restricted-likelihood: -42.21856
  Fixed: score ~ time 
(Intercept)      timet2      timet3 
  17.013333   -2.000000   -3.453333 

Random effects:
 Formula: ~1 | id
        (Intercept)  Residual
StdDev:    1.344507 0.3034458

Number of Observations: 45
Number of Groups: 15 
</pre></div>
</div>
</div>
</div>
<p>Where we can see some fitting details, such as the estimation method (restricted maximum likelihood, or REML), the number of data points and the number of grouping structures we used (in this case, 15 subjects). We can also see the estimates of the <em>fixed-effects</em> as well as the variance terms calculated from the random effects (given as standard deviations).</p>
<p>The <em>fixed-effects</em> are interpreted in the same way as with <code class="docutils literal notranslate"><span class="pre">lm()</span></code>. Because <code class="docutils literal notranslate"><span class="pre">time</span></code> is categorical, <code class="docutils literal notranslate"><span class="pre">R</span></code> has converted it to a dummy variable. To make the model identifiable, <code class="docutils literal notranslate"><span class="pre">time1</span></code> has been dropped (<span class="math notranslate nohighlight">\(\alpha_{1} = 0\)</span>), so we have a dummy for <code class="docutils literal notranslate"><span class="pre">time2</span></code> and a dummy for <code class="docutils literal notranslate"><span class="pre">time3</span></code>. The <code class="docutils literal notranslate"><span class="pre">(Intercept)</span></code> parameter is therefore the mean value of <code class="docutils literal notranslate"><span class="pre">score</span></code> for <code class="docutils literal notranslate"><span class="pre">time1</span></code>, the <code class="docutils literal notranslate"><span class="pre">time2</span></code> parameter is the difference <code class="docutils literal notranslate"><span class="pre">time2</span> <span class="pre">-</span> <span class="pre">time1</span></code>, and the <code class="docutils literal notranslate"><span class="pre">time3</span></code> parameter is the difference <code class="docutils literal notranslate"><span class="pre">time3</span> <span class="pre">-</span> <span class="pre">time1</span></code>. This is exactly the same as we have seen previously with any linear model containing a categorical predictor variable. The <em>fixed-effects</em> therefore give us our predictions for the <em>marginal</em> means. In other words, when we <em>average across</em> the subjects. These are the model predictions for the population-level effects, in the same way that they would from a usual call to <code class="docutils literal notranslate"><span class="pre">lme()</span></code>.</p>
<p>The difference of course is that we now also have the <em>random-effects</em>. We can think of these as <em>error-terms</em>, either using an LME conceptualisation of a model with <em>multiple</em> errors, or using a multilevel conceptualisation of different errors at each <em>level</em> of the data hierarchy. Importantly, what the random-effects add to the model is not any change to the mean function, rather they create <em>additional variance terms</em>. The two random elements are</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{alignat*}{1}
    \xi_{i}   &amp;\sim \mathcal{N}\left(0,\sigma^{2}_{b}\right) \\
    \eta_{ij} &amp;\sim \mathcal{N}\left(0,\sigma^{2}_{w}\right),
\end{alignat*}
\end{split}\]</div>
<p>so estimating their expected value would be silly anyway, as it is 0 in both cases. Instead, we want to <em>use</em> the random effects to estimate <span class="math notranslate nohighlight">\(\sigma^{2}_{b}\)</span> and <span class="math notranslate nohighlight">\(\sigma^{2}_{w}\)</span>. This is no different to the errors in a normal linear model, which are used to estimate <span class="math notranslate nohighlight">\(\sigma^{2}\)</span>. The difference now is that this overall variance has been <em>partitioned</em> into <span class="math notranslate nohighlight">\(\sigma^{2} = \sigma^{2}_{b} + \sigma^{2}_{w}\)</span>.</p>
<p>The estimated variance components are given in the output above under <code class="docutils literal notranslate"><span class="pre">Random</span> <span class="pre">effects:</span></code>. The <code class="docutils literal notranslate"><span class="pre">(Intercept)</span></code> term corresponds to <span class="math notranslate nohighlight">\(\xi_{i}\)</span> and thus the estimate of <span class="math notranslate nohighlight">\(\sigma^{2}_{b} = 1.34^{2} = 1.80\)</span>. The <code class="docutils literal notranslate"><span class="pre">Residual</span></code> term corresponds to <span class="math notranslate nohighlight">\(\eta_{ij}\)</span> and thus the estimate of <span class="math notranslate nohighlight">\(\sigma^{2}_{w} = 0.30^{2} = 0.09\)</span>. As expected, the within-subject variance is much smaller than the between-subject, as people tend to exhibit a degree of <em>internally consistency</em> but can differ wildly from others.</p>
<p>We can also have a look at the realised values of the random effects, using the <code class="docutils literal notranslate"><span class="pre">random.effects()</span></code> function.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">random.effects</span><span class="p">(</span><span class="n">lme.mod</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>   (Intercept)
31  -2.0605689
32  -1.8639080
33  -2.0933457
34  -1.2083718
35  -0.8150501
36  -0.1922906
37   0.4632456
38   0.4304688
39   0.6271297
40   0.2010311
41   0.8565674
42   0.5943529
43   1.6104340
44   1.4465500
45   2.0037558
</pre></div>
</div>
</div>
</div>
<p>These are the estimated values of <span class="math notranslate nohighlight">\(\xi_{i}\)</span> in this model and can be interpreted as <em>subject-specific</em> deflections from the population mean. For instance, <span class="math notranslate nohighlight">\(\xi_{1} = -2.06\)</span>. This means that irrespective of the value of <code class="docutils literal notranslate"><span class="pre">time</span></code>, subject 1 is predicted to sit <em>below</em> the population average by 2.06 points on the self-esteem scale. So, the predicted population mean for <code class="docutils literal notranslate"><span class="pre">time1</span></code> in this model is given by</p>
<div class="math notranslate nohighlight">
\[
\hat{y}_{i1} = \hat{\mu} + \hat{\alpha}_{1} = \hat{\mu} = 17.01,
\]</div>
<p>irrespective of subject. However, the <em>conditional</em> mean for subject 1 is</p>
<div class="math notranslate nohighlight">
\[
\hat{y}_{11} = \hat{\mu} + \hat{\alpha}_{1} + \xi_{1} = 17.01 - 2.06 = 14.95.
\]</div>
<p>So subject 1’s personal offset is that they always score <em>lower</em> than the population average. The effect of <code class="docutils literal notranslate"><span class="pre">time</span></code> is therefore the same, they just fundamentally have lower self-esteem than average.</p>
<p>We can do this for any of the subjects, however, we do not really care about the realised values of <span class="math notranslate nohighlight">\(\xi_{i}\)</span>. These are a means to an end. Because they are considered <em>random</em>, their actual numeric value is not important. What <em>is</em> important is what they can tell us about the population they are drawn from. Because these are <em>deflections</em> and their expected value is 0, their mean is of little interest</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">mean</span><span class="p">(</span><span class="nf">random.effects</span><span class="p">(</span><span class="n">lme.mod</span><span class="p">)[,</span><span class="m">1</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[1] 5.112548e-15
</pre></div>
</div>
</div>
</div>
<p>As we can see, this is effectively 0. Instead, what we want to know is how much the subject-specific deflections <em>vary</em>. Their <em>spread</em> tells us how much the subjects differ from each other and thus provides an estimate of <span class="math notranslate nohighlight">\(\sigma^{2}_{b}\)</span>. So, we can instead calculate</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">var</span><span class="p">(</span><span class="nf">random.effects</span><span class="p">(</span><span class="n">lme.mod</span><span class="p">)[,</span><span class="m">1</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[1] 1.777518
</pre></div>
</div>
</div>
</div>
<p>The same is true of the residual errors, which are also mean 0 and can be used to estimate <span class="math notranslate nohighlight">\(\sigma^{2}_{w}\)</span>.</p>
<p>We can look at both of these effects side-by-side by plotting their distributions. Remember, the theory states that</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{alignat*}{1}
    \xi_{i}   &amp;\sim \mathcal{N}\left(0,\sigma^{2}_{b}\right) \\
    \eta_{ij} &amp;\sim \mathcal{N}\left(0,\sigma^{2}_{w}\right),
\end{alignat*}
\end{split}\]</div>
<p>so we expect these to both approximate a normal distribution with mean 0 and some spread that is of interest to us. We plot both of these below as histograms a normal QQ-plots</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">xi.i</span><span class="w">   </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">random.effects</span><span class="p">(</span><span class="n">lme.mod</span><span class="p">)[,</span><span class="m">1</span><span class="p">]</span>
<span class="n">eta.ij</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">residuals</span><span class="p">(</span><span class="n">lme.mod</span><span class="p">)</span>

<span class="nf">par</span><span class="p">(</span><span class="n">mfrow</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">2</span><span class="p">,</span><span class="m">2</span><span class="p">))</span>

<span class="c1"># plot xi.i</span>
<span class="nf">hist</span><span class="p">(</span><span class="n">xi.i</span><span class="p">,</span><span class="w"> </span><span class="n">xlim</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">-3</span><span class="p">,</span><span class="m">3</span><span class="p">))</span>
<span class="nf">qqnorm</span><span class="p">(</span><span class="n">xi.i</span><span class="p">)</span>
<span class="nf">qqline</span><span class="p">(</span><span class="n">xi.i</span><span class="p">)</span>

<span class="c1"># plot eta.ij</span>
<span class="nf">hist</span><span class="p">(</span><span class="n">eta.ij</span><span class="p">,</span><span class="w"> </span><span class="n">xlim</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="m">-3</span><span class="p">,</span><span class="m">3</span><span class="p">))</span>
<span class="nf">qqnorm</span><span class="p">(</span><span class="n">eta.ij</span><span class="p">)</span>
<span class="nf">qqline</span><span class="p">(</span><span class="n">eta.ij</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="_images/2bb570d785d5c55987fdadf56777cbb23dde912208ac59ff16565f8757fa9631.png" src="_images/2bb570d785d5c55987fdadf56777cbb23dde912208ac59ff16565f8757fa9631.png" />
</div>
</div>
<p>Although the amount of data in this example makes the distributional form harder to verify, the key elements to notice here are that both distributions are centred on 0. So the expected values of both <span class="math notranslate nohighlight">\(\xi_{i}\)</span> and <span class="math notranslate nohighlight">\(\eta_{ij}\)</span> are 0. This is why the expected population effect is driven purely by the fixed-effects because, on average, the errors are 0. Secondly, the distribution of <span class="math notranslate nohighlight">\(\xi_{i}\)</span> is <em>much wider</em> than the distribution of <span class="math notranslate nohighlight">\(\eta_{ij}\)</span>. This is because the distribution of <span class="math notranslate nohighlight">\(\xi_{i}\)</span> reflects measurements from <em>different subjects</em> and the distribution of <span class="math notranslate nohighlight">\(\eta_{ij}\)</span> reflects measurements from the <em>same subject</em>.</p>
<p>We can also see the fundamental assumption behind treating <code class="docutils literal notranslate"><span class="pre">id</span></code> as a <em>random-effect</em>. When we do this, we conceptualise each level of <code class="docutils literal notranslate"><span class="pre">id</span></code> as a random draw from a larger population of subjects. We therefore assume some distributional form for the <em>subject</em> effects and estimate its variance. This is the distribution we see in the plot above. If we instead treated <code class="docutils literal notranslate"><span class="pre">id</span></code> as a <em>fixed-effect</em>, we assume that each of its levels represents some population-level constant that we want to estimate. There would be no distribution and no variance to estimate. We would be effectively saying that we are only interested in <em>these subjects</em> and no one else. We want to <em>precisely</em> know the mean of <code class="docutils literal notranslate"><span class="pre">id</span> <span class="pre">==</span> <span class="pre">'32'</span></code> and make comparisons and inference on <code class="docutils literal notranslate"><span class="pre">id</span> <span class="pre">==</span> <span class="pre">32</span></code> compared to <code class="docutils literal notranslate"><span class="pre">id</span> <span class="pre">==</span> <span class="pre">42</span></code> or <code class="docutils literal notranslate"><span class="pre">id</span> <span class="pre">==</span> <span class="pre">44</span></code> or between any pairs of subjects. It would be like treating the levels of <code class="docutils literal notranslate"><span class="pre">id</span></code> in the same way as the levels of <code class="docutils literal notranslate"><span class="pre">time</span></code>. Although there may be cases where the subjects that you have are <em>special</em> and each one is <em>meaningful</em> on their own, this is not our usual aim when we collect a sample. So, for most experiments, the subjects <em>have</em> to be treated as a <em>random-effect</em> in order to make sense.</p>
</section>
</section>
<section id="inference-in-mixed-effects-models">
<h2>Inference in Mixed-effects Models<a class="headerlink" href="#inference-in-mixed-effects-models" title="Link to this heading">#</a></h2>
<p>As a final topic in this lesson, we return to the controversial subject of <em>inference</em>. As we know from previous lessons, assuming a more general form for the covariance structure <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}\)</span> causes problems for the classical inferential framework. This is precisely because the distributions of the variance terms are no longer known. Traditionally, the variance has a scaled <span class="math notranslate nohighlight">\(\chi^{2}\)</span> distribution, whose width is parameterised by the degrees of freedom. Without this, the null distribution of the tests statics are unknown and the whole concept of error degrees of freedom disappears from our testing framework. Recall as well that there were then 3 possible solutions to this problem:</p>
<ul class="simple">
<li><p>Assume we know <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}\)</span> and carry on as usual</p></li>
<li><p>Assume we know <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}\)</span>, but only because we have enough data and can use <em>asymptotic</em> results</p></li>
<li><p>Compensate by calculating <em>effective</em> degrees of freedom</p></li>
</ul>
<p>To begin with, we will briefly explore why all this remains relevant for mixed-effects models, by showing that a mixed-effects model is <em>equivalent</em> to a GLS model.</p>
<section id="the-implied-marginal-model">
<h3>The Implied Marginal Model<a class="headerlink" href="#the-implied-marginal-model" title="Link to this heading">#</a></h3>
<p>Although we have been working on the basis that a hierarchical/LME model does not require direct consideration of the covariance structure, the covariance structure <em>still exists</em>. Unlike GLS, this structure is <em>implied</em> rather than directly specified. Nonetheless, we saw earlier in our simulations that a given covariance structure will emerge as a property of the random effects. Because of this, we can think of an LME model as <em>implying</em> the following <em>marginal</em> model of the data</p>
<div class="math notranslate nohighlight">
\[
\mathbf{y}_{i} \sim \mathcal{N}\left(\boldsymbol{\mu},\boldsymbol{\Sigma}_{i}\right),
\]</div>
<p>where we are assuming that <span class="math notranslate nohighlight">\(\mathbf{y}_{i}\)</span> is the vector of repeated measurements from subject <span class="math notranslate nohighlight">\(i\)</span>, <span class="math notranslate nohighlight">\(\boldsymbol{\mu}\)</span> is the vector of population means for the repeated measures and <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}_{i}\)</span> is block <span class="math notranslate nohighlight">\(i\)</span> from the full covariance structure. Remember, this is <em>marginal</em> because the mean structure is the average across <em>all subjects</em>, rather than <em>conditional</em> on this specific subject. Of importance, is that <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}_{i}\)</span> can be formed <em>directly</em> from the random-effects. The way this is done requires more explanation of how LME models can be expressed using matrix notation and so is somewhat beyond our current score. Nevertheless, we can understand this from what we have seen previously where</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{alignat*}{1}
    \text{Var}\left(y_{ij}\right) &amp;= \sigma^{2}_{b} + \sigma^{2}_{w} \\
    \text{Cov}\left(y_{ij},y_{ij^{\prime}}\right) &amp;= \sigma^{2}_{b} \\
\end{alignat*}
\end{split}\]</div>
<p>which implies a compound symmetric structure based on the random effects alone. The big-picture conclusion here is that an LME model <em>is the same as GLS</em>, but with a more sophisticated way of constructing the variance-covariance matrix using the random effects. This leads to some important conclusions:</p>
<ol class="arabic simple">
<li><p>The concept of <em>removing</em> the covariance structure and then estimating the fixed-effects remains the <em>same</em> under an LME model.</p></li>
<li><p>The inferential issues around GLS are <em>identical</em> for LME models.</p></li>
<li><p>The covariance structure is <em>more restricted</em> under LME models, because it is constrained by the random effects themselves.</p></li>
</ol>
</section>
<section id="the-marginal-covariance-structure">
<h3>The Marginal Covariance Structure<a class="headerlink" href="#the-marginal-covariance-structure" title="Link to this heading">#</a></h3>
<p>We can see all this visually using our model fit with <code class="docutils literal notranslate"><span class="pre">lme()</span></code>. In the code below, we use the <code class="docutils literal notranslate"><span class="pre">getVarCov()</span></code> function to again extract the marginal covariance matrix for a particular value of <code class="docutils literal notranslate"><span class="pre">id</span></code> and then visualise it.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">library</span><span class="p">(</span><span class="s">&#39;Matrix&#39;</span><span class="p">)</span>

<span class="n">Sigma</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">getVarCov</span><span class="p">(</span><span class="n">lme.mod</span><span class="p">,</span><span class="w"> </span><span class="n">individual</span><span class="o">=</span><span class="s">&#39;31&#39;</span><span class="p">,</span><span class="w"> </span><span class="n">type</span><span class="o">=</span><span class="s">&#39;marginal&#39;</span><span class="p">)</span>
<span class="n">Sigma</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">as.matrix</span><span class="p">(</span><span class="n">Sigma</span><span class="o">$</span><span class="n">`31`</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="n">Sigma</span><span class="p">)</span>
<span class="nf">image</span><span class="p">(</span><span class="nf">as</span><span class="p">(</span><span class="n">Sigma</span><span class="p">,</span><span class="s">&#39;Matrix&#39;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>         1        2        3
1 1.899778 1.807698 1.807698
2 1.807698 1.899778 1.807698
3 1.807698 1.807698 1.899778
</pre></div>
</div>
<img alt="_images/64018c114f880f473de3827b3830087f33036bcdb6692b24664339ef6894b9c0.png" src="_images/64018c114f880f473de3827b3830087f33036bcdb6692b24664339ef6894b9c0.png" />
</div>
</div>
<p>As expected, this is <em>compound symmetric</em>, though this is now <em>implied</em> by the random-effects, rather than specified directly as we did with GLS. We can also use the function defined in the drop-down below to construct the <em>full</em> covariance matrix <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}\)</span>, using the details about the model structure in the model object returned by <code class="docutils literal notranslate"><span class="pre">lme()</span></code>.</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">library</span><span class="p">(</span><span class="s">&#39;Matrix&#39;</span><span class="p">)</span>

<span class="n">fullVarCov</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="kr">function</span><span class="p">(</span><span class="n">fit</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">grouping_var_name</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">names</span><span class="p">(</span><span class="n">fit</span><span class="o">$</span><span class="n">groups</span><span class="p">)[</span><span class="m">1</span><span class="p">]</span><span class="w"> </span><span class="c1"># get grouping variable name (e.g &quot;id&quot;)</span>
<span class="w">  </span><span class="n">groups</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">fit</span><span class="o">$</span><span class="n">data</span><span class="p">[[</span><span class="n">grouping_var_name</span><span class="p">]]</span><span class="w">   </span><span class="c1"># use name to get grouping variable</span>
<span class="w">  </span><span class="n">groups</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">unique</span><span class="p">(</span><span class="nf">as.character</span><span class="p">(</span><span class="n">groups</span><span class="p">))</span><span class="w">    </span><span class="c1"># reduce grouping variable to unique values</span>

<span class="w">  </span><span class="c1"># for each unique grouping variable value, extract the covariance matrices</span>
<span class="w">  </span><span class="n">blocks</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">lapply</span><span class="p">(</span><span class="n">groups</span><span class="p">,</span><span class="w"> </span><span class="kr">function</span><span class="p">(</span><span class="n">gi</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">S</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">getVarCov</span><span class="p">(</span><span class="n">fit</span><span class="p">,</span><span class="w"> </span><span class="n">individual</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">gi</span><span class="p">,</span><span class="w"> </span><span class="n">type</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;marginal&quot;</span><span class="p">)</span>
<span class="w">    </span><span class="kr">if</span><span class="w"> </span><span class="p">(</span><span class="nf">is.list</span><span class="p">(</span><span class="n">S</span><span class="p">))</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">S</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">S</span><span class="p">[[</span><span class="n">gi</span><span class="p">]]</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="nf">as.matrix</span><span class="p">(</span><span class="n">S</span><span class="p">)</span>
<span class="w">  </span><span class="p">})</span>

<span class="w">  </span><span class="c1"># put the covariance matrices into blocks</span>
<span class="w">  </span><span class="n">V</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">bdiag</span><span class="p">(</span><span class="n">blocks</span><span class="p">)</span>
<span class="w">  </span><span class="n">V</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</details>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">Big.Sigma</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">fullVarCov</span><span class="p">(</span><span class="n">lme.mod</span><span class="p">)</span>
<span class="nf">image</span><span class="p">(</span><span class="n">Big.Sigma</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/1cafa04af6b99b9ab3d3febeed41d784cb86d9846f58355833ad41db8b53f329.png" src="_images/1cafa04af6b99b9ab3d3febeed41d784cb86d9846f58355833ad41db8b53f329.png" />
</div>
</div>
<p>So we can see that this is indeed block-diagonal, with a compound symmetric structure per-subject and zeros everywhere else.</p>
<p>Although we are somewhat focusing on shared <em>disadvantages</em>, it is important to recognise that all the <em>advantages</em> of GLS are also still here. For instance, the correct error term for each test can be automatically generated from the covariance structure. So while a model may be no better than the repeated measures ANOVA in its covariance assumptions, it is infinitely <em>more practical</em> because we do not need to mess around manually assigning error terms to different tests (and worrying about getting this wrong).</p>
<p>Additionally, the connection between the random-effects and the covariance structure implies that <em>more complex</em> random-effect specifications will lead to different covariance structures. Indeed, this is exactly the case. Where this is useful is when we have more complex data structures. Because the random-effects are a direct consequence of the structure of the data, the structure drives the covariance pattern. This means we do not have to reason about what pattern we want and whether we can express this to a function like <code class="docutils literal notranslate"><span class="pre">gls()</span></code>. Instead, we supply the data structure through the random-effects and the covariance is built for us, no matter its complexity. This is something that will become clearer when we start exploring more complex data structures <em>next week</em>.</p>
</section>
<section id="inference-using-nlme">
<h3>Inference Using <code class="docutils literal notranslate"><span class="pre">nlme</span></code><a class="headerlink" href="#inference-using-nlme" title="Link to this heading">#</a></h3>
<p>Now, let us get back to the <em>practical</em> topic of inference using LME models in <code class="docutils literal notranslate"><span class="pre">R</span></code>. To begin, we can call <code class="docutils literal notranslate"><span class="pre">summary()</span></code> on the model object returned by <code class="docutils literal notranslate"><span class="pre">lme()</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">summary</span><span class="p">(</span><span class="n">lme.mod</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Linear mixed-effects model fit by REML
  Data: anxiety.long 
       AIC      BIC    logLik
  94.43711 103.1255 -42.21856

Random effects:
 Formula: ~1 | id
        (Intercept)  Residual
StdDev:    1.344507 0.3034458

Fixed effects:  score ~ time 
                Value Std.Error DF   t-value p-value
(Intercept) 17.013333 0.3558818 28  47.80614       0
timet2      -2.000000 0.1108027 28 -18.05009       0
timet3      -3.453333 0.1108027 28 -31.16650       0
 Correlation: 
       (Intr) timet2
timet2 -0.156       
timet3 -0.156  0.500

Standardized Within-Group Residuals:
       Min         Q1        Med         Q3        Max 
-1.5378504 -0.4924282  0.1284212  0.6647537  1.9114200 

Number of Observations: 45
Number of Groups: 15 
</pre></div>
</div>
</div>
</div>
<p>As we can see, this returns an output very similar to what we have seen before from <code class="docutils literal notranslate"><span class="pre">lm()</span></code> and <code class="docutils literal notranslate"><span class="pre">gls()</span></code>. The main additional information we have compared to simply printing the model (as we did earlier) is the table of coefficients associated with the <em>fixed-effects</em>. However, notice two important details from the <code class="docutils literal notranslate"><span class="pre">gls()</span></code> output</p>
<ol class="arabic simple">
<li><p>Degrees of freedom and <span class="math notranslate nohighlight">\(t\)</span>-statistics are given, so this is <em>not</em> using and asymptotic approximation</p></li>
<li><p>The degrees of freedom are <em>not</em> based on assuming that <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}\)</span> is known as they are <em>smaller</em> than those reported by <code class="docutils literal notranslate"><span class="pre">gls()</span></code>.</p></li>
</ol>
<p>So, what is this output doing? It is using <em>effective</em> degrees of freedom to specify the tests, using the <em>structure</em> built-in to the LME model. Now, the method used is fairly basic and is given by a heuristic described more fully in <a class="reference external" href="https://www.google.co.uk/books/edition/Mixed_Effects_Models_in_S_and_S_PLUS/y54QDUTmvDcC?hl=en&amp;amp;gbpv=1&amp;amp;dq=pinheiro+and+bates+2000&amp;amp;printsec=frontcover">Pinheiro and Bates (2000, pg.91)</a>. Nevertheless, this tells us something important about LME models. Because the data structure is embedded in the model specification, we can more readily use this structure to make better approximations to the uncertainty around the variance terms. A GLS model has <em>no knowledge</em> of the structure. It just see a single covariance matrix of any structure that it can remove. So even though the heuristic used by <code class="docutils literal notranslate"><span class="pre">lme()</span></code> is a very basic approximation, it does agree with the classical specification of degrees of freedom in a repeated measures ANOVA. So, at the <em>very least</em> we are back in familiar territory.</p>
</section>
</section>
<section id="anova-tables-and-follow-up-tests">
<h2>ANOVA Tables and Follow-up Tests<a class="headerlink" href="#anova-tables-and-follow-up-tests" title="Link to this heading">#</a></h2>
<p>As we know, the typical approach when using a factor with &gt; 2 levels is to examine the <em>omnibus</em> tests via the ANOVA table. As we also know, under least-squares, the ANOVA can be conceptualised as a model comparisons procedure. Although the same is true <em>conceptually</em> with a LME model, there are added complications from the random-effects. We will discuss these more in the associated workshop. For now, we will just see what we get from using <code class="docutils literal notranslate"><span class="pre">Anova()</span></code> to generate the omnibus tests.</p>
<section id="omnibus-tests-from-anova">
<h3>Omnibus Tests From <code class="docutils literal notranslate"><span class="pre">Anova()</span></code><a class="headerlink" href="#omnibus-tests-from-anova" title="Link to this heading">#</a></h3>
<p>As we know, the <code class="docutils literal notranslate"><span class="pre">Anova()</span></code> function from <code class="docutils literal notranslate"><span class="pre">car</span></code> is our preferred method of generating omnibus tests because of its flexibility under imbalance and its preference for Type II tests. None of that changes within the world of LME models. If we use <code class="docutils literal notranslate"><span class="pre">Anova()</span></code> on our example model, we get</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">library</span><span class="p">(</span><span class="n">car</span><span class="p">)</span>
<span class="nf">Anova</span><span class="p">(</span><span class="n">lme.mod</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Analysis of Deviance Table (Type II tests)

Response: score
      Chisq Df Pr(&gt;Chisq)    
time 979.46  2  &lt; 2.2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
</pre></div>
</div>
</div>
</div>
<p>So, notice that, much like a <code class="docutils literal notranslate"><span class="pre">gls()</span></code> model, we <em>do not</em> get effective degrees of freedom here. Instead, we have asymptotic <span class="math notranslate nohighlight">\(\chi^{2}\)</span> tests. So, again, we get an unfortunate conceptual mismatch between the coefficient tests produced by <code class="docutils literal notranslate"><span class="pre">lme()</span></code> and the omnibus tests produced by <code class="docutils literal notranslate"><span class="pre">Anova()</span></code>. Although a bit awkward, this is not fundamentally a problem because</p>
<ul class="simple">
<li><p>We will rarely be using <em>both</em> sets of tests. Even for models <em>without</em> any factors, we can still call <code class="docutils literal notranslate"><span class="pre">Anova()</span></code> to produce the asymptotic tests for the coefficients.</p></li>
<li><p>If we want to use asymptotic versions of coefficient tests we can just ignore the <span class="math notranslate nohighlight">\(p\)</span>-value and the given degrees of freedom and instead calculate <code class="docutils literal notranslate"><span class="pre">2</span> <span class="pre">*</span> <span class="pre">pnorm(abs(t),</span> <span class="pre">lower.tail=FALSE)</span></code>. This will give us <span class="math notranslate nohighlight">\(p\)</span>-values based on treating the tests as a <span class="math notranslate nohighlight">\(z\)</span>-statistic rather than a <span class="math notranslate nohighlight">\(t\)</span>-statistic.</p></li>
</ul>
<p>So it <em>is</em> possible to keep our inferential framework consistent. The main downside is that <code class="docutils literal notranslate"><span class="pre">Anova()</span></code> has no other options, meaning we are <em>forced</em> into asymptotics, whether we like it or not. This is not true of <code class="docutils literal notranslate"><span class="pre">lme4</span></code> models, as discussed in the drop-down below.</p>
<div class="tip dropdown admonition">
<p class="admonition-title">Tests Using lme4</p>
<p>Although we have not covered the <code class="docutils literal notranslate"><span class="pre">lme4</span></code> package, one advantage of using it over <code class="docutils literal notranslate"><span class="pre">nlme</span></code> is that effective degrees of freedom methods are more readily available. This means we can keep a more consistent inferential framework using more familiar <span class="math notranslate nohighlight">\(t\)</span>-statistics and <span class="math notranslate nohighlight">\(F\)</span>-statistics. By default, <code class="docutils literal notranslate"><span class="pre">lme4</span></code> provides <em>no</em> <span class="math notranslate nohighlight">\(p\)</span>-values, because the authors simply do not want to commit to one particular approximation, nor try to “cover up” the inferential problems with LME models. However, other packages such as <code class="docutils literal notranslate"><span class="pre">lmerTest</span></code> and <code class="docutils literal notranslate"><span class="pre">pbkrtest</span></code> have been developed to provide these inferential options on top of <code class="docutils literal notranslate"><span class="pre">lme4</span></code>. These are then leveraged by <code class="docutils literal notranslate"><span class="pre">car</span></code> and we can use <code class="docutils literal notranslate"><span class="pre">Anova(lme4.mod,</span> <span class="pre">test.statistic='F')</span></code> to get <span class="math notranslate nohighlight">\(F\)</span>-statistics with effective degrees of freedom. Although this is all potentially more useful than the results from <code class="docutils literal notranslate"><span class="pre">nlme</span></code>, the <code class="docutils literal notranslate"><span class="pre">lme4</span></code> package does have some <em>disadvantages</em>. The biggest is that we cannot model the covariance structure of the residuals. Practically, this means we cannot specify models with different variances per-group and so have to assume homogeneity of variance for any between-subjects factors in the model. This is particularly problematic when our groups may be Patients vs Controls. This is not true of <code class="docutils literal notranslate"><span class="pre">nlme</span></code>, as we will see in the associated workshop. So we need to decide between <em>modelling flexibility</em> and <em>inferential flexibility</em>. Sadly, at this point in time, we cannot have both.</p>
</div>
</section>
<section id="follow-up-tests-from-emmeans">
<h3>Follow-up Tests From <code class="docutils literal notranslate"><span class="pre">emmeans()</span></code><a class="headerlink" href="#follow-up-tests-from-emmeans" title="Link to this heading">#</a></h3>
<p>Finally, we can use the same approach as we have seen previously with both <code class="docutils literal notranslate"><span class="pre">lm()</span></code> and <code class="docutils literal notranslate"><span class="pre">gls()</span></code> to perform follow-up tests using <code class="docutils literal notranslate"><span class="pre">emmeans</span></code>. Given that we are constrained by <code class="docutils literal notranslate"><span class="pre">Anova()</span></code> to using asymptotic methods, we need to use the <code class="docutils literal notranslate"><span class="pre">mode='asymptotic'</span></code> argument to keep our inferential framework consistent. Otherwise, this is business as usual.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">library</span><span class="p">(</span><span class="s">&#39;emmeans&#39;</span><span class="p">)</span>
<span class="n">emm</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">emmeans</span><span class="p">(</span><span class="n">lme.mod</span><span class="p">,</span><span class="w"> </span><span class="n">pairwise</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">time</span><span class="p">,</span><span class="w"> </span><span class="n">mode</span><span class="o">=</span><span class="s">&#39;asymptotic&#39;</span><span class="p">,</span><span class="w"> </span><span class="n">adjust</span><span class="o">=</span><span class="s">&#39;holm&#39;</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">emm</span><span class="o">$</span><span class="n">contrasts</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> contrast estimate    SE  df z.ratio p.value
 t1 - t2      2.00 0.111 Inf  18.050  &lt;.0001
 t1 - t3      3.45 0.111 Inf  31.166  &lt;.0001
 t2 - t3      1.45 0.111 Inf  13.116  &lt;.0001

Degrees-of-freedom method: fixed 
P value adjustment: holm method for 3 tests 
</pre></div>
</div>
</div>
</div>
<aside class="topic">
<p class="topic-title">What do you now know?</p>
<p>In this section, we have explored using the <code class="docutils literal notranslate"><span class="pre">nlme</span></code> package to fit mixed-effects models using the <code class="docutils literal notranslate"><span class="pre">lme()</span></code> function. After reading this section, you should have a good sense of:</p>
<ul class="simple">
<li><p>…</p></li>
<li><p>…</p></li>
<li><p>…</p></li>
</ul>
</aside>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "r"
        },
        kernelOptions: {
            name: "ir",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'ir'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="4.multilevel-to-mixed.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">From Multilevel to Mixed-effects</p>
      </div>
    </a>
    <a class="right-next"
       href="summary.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Summary</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fitting-mixed-effects-models-with-nlme">Fitting Mixed-effects Models with <code class="docutils literal notranslate"><span class="pre">nlme</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#specifying-random-effects">Specifying Random-effects</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exploring-the-lme-output">Exploring the <code class="docutils literal notranslate"><span class="pre">lme()</span></code> Output</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#inference-in-mixed-effects-models">Inference in Mixed-effects Models</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-implied-marginal-model">The Implied Marginal Model</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-marginal-covariance-structure">The Marginal Covariance Structure</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#inference-using-nlme">Inference Using <code class="docutils literal notranslate"><span class="pre">nlme</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#anova-tables-and-follow-up-tests">ANOVA Tables and Follow-up Tests</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#omnibus-tests-from-anova">Omnibus Tests From <code class="docutils literal notranslate"><span class="pre">Anova()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#follow-up-tests-from-emmeans">Follow-up Tests From <code class="docutils literal notranslate"><span class="pre">emmeans()</span></code></a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Dr Martyn McFarquhar
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2026.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>