{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a6b3fd6-1753-45e7-a920-fccf68cbdcac",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# The Multilevel Framework\n",
    "We will start our journey into the world of mixed-effects models from the perspective of a *multilevel* model. This is primarily because we can build the pieces of a mixed-effects model very slowly from first principles. In addition, the multilevel framework is often the most *intuitive* way to think about these models, they are just rarely implemented in this fashion. .... Remember as well, we will use the term *multilevel* throughout, but the term *hierarchical* is entirely equivalent. So, if anyone ever says \"hierarchical linear model\" to you, you just need to do a mental substitution for the term \"multilevel linear model\". They mean exactly the same thing.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca08be4",
   "metadata": {},
   "source": [
    "## Fitting a Model to One Subject\n",
    "To begin with, let us imagine that we only have the data for a *single subject*. What kind of model could we fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fffe213",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "library('datarium')\n",
    "library('reshape2')\n",
    "\n",
    "data('selfesteem')\n",
    "\n",
    "# repeats and number of subjects\n",
    "t <- 3\n",
    "n <- dim(selfesteem)[1]\n",
    "\n",
    "# reshape wide -> long\n",
    "selfesteem.long <- melt(selfesteem,            # wide data frame\n",
    "                        id.vars='id',          # what stays fixed?\n",
    "                        variable.name=\"time\",  # name for the new predictor\n",
    "                        value.name=\"score\")    # name for the new outcome\n",
    "\n",
    "selfesteem.long           <- selfesteem.long[order(selfesteem.long$id),] # order by ID\n",
    "rownames(selfesteem.long) <- seq(1,n*t)                                  # fix row names\n",
    "selfesteem.long$id        <- as.factor(selfesteem.long$id)               # convert ID to factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d574a62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  id time    score\n",
      "1  1   t1 4.005027\n",
      "2  1   t2 5.182286\n",
      "3  1   t3 7.107831\n"
     ]
    }
   ],
   "source": [
    "sub.1 <- selfesteem.long[selfesteem.long$id == '1',]\n",
    "print(sub.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868adff1",
   "metadata": {},
   "source": [
    "So, our key question here is what model is possible?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d4676d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = score ~ time, data = sub.1)\n",
       "\n",
       "Residuals:\n",
       "ALL 3 residuals are 0: no residual degrees of freedom!\n",
       "\n",
       "Coefficients:\n",
       "            Estimate Std. Error t value Pr(>|t|)\n",
       "(Intercept)    4.005        NaN     NaN      NaN\n",
       "timet2         1.177        NaN     NaN      NaN\n",
       "timet3         3.103        NaN     NaN      NaN\n",
       "\n",
       "Residual standard error: NaN on 0 degrees of freedom\n",
       "Multiple R-squared:      1,\tAdjusted R-squared:    NaN \n",
       "F-statistic:   NaN on 2 and 0 DF,  p-value: NA\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.sub.1 <- lm(score ~ time, data=sub.1)\n",
    "summary(lm.sub.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b6fb62",
   "metadata": {},
   "source": [
    "... So, notice that if we allow the model to freely estimate the effect of `condition`, it will fit the data *perfectly* and there will be no error. This tells us that we cannot let this effect be unique to each subject because the data does not support it. So, in this instance, the data constrains us to the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37914e0a",
   "metadata": {},
   "source": [
    "\n",
    "## Extending the Model to Multiple Subjects\n",
    "But of course, we do not *only* have subject 1. So let us now do the same thing with subject 2 ...\n",
    "\n",
    "$$\n",
    "$$\n",
    "\n",
    "So, we now have these two models separately, but notice that we *can* now estimate the effect of `time` because we have replications of `time` *across* the subjects. So now, we can think of these two models as\n",
    "\n",
    "$$\n",
    "\\begin{alignat*}{1}\n",
    "    y_{1j} &= \\mu_{1} + \\alpha_{j} + \\eta_{1j} \\\\\n",
    "    y_{2j} &= \\mu_{2} + \\alpha_{j} + \\eta_{2j} \\\\\n",
    "\\end{alignat*}\n",
    "$$\n",
    "\n",
    "which, across all subjects, just gives us\n",
    "\n",
    "$$\n",
    "y_{ij} = \\mu_{i} + \\alpha_{j} + \\eta_{ij}.\n",
    "$$\n",
    "\n",
    "So, we now have *subject-specific* means ($\\mu_{1}, \\mu_{2}, \\dots, \\mu_{n}$) and an effect of `time` ($\\alpha_{j}$). But notice that there is no subject index on this effect. So it is *the same* irrespective of the specific subject. This is important because it indicates that $\\alpha_{j}$ captures something *universal* from across all subjects, which is precisely what we want in terms of understanding the effect of `time` on the self-esteem `score`.\n",
    "\n",
    "In order to understand where we go from here, imagine that we ran the experiment *again* and collected a new subject. What do we think would change? Well, certainly the term $\\mu_{i}$. We have different data now and so the grand mean is almost certainly going to change. What else? Well, the errors will also change, as we would expect. What would not change would be $\\alpha_{j}$, because we have assumed that this is *constant* across subjects. So, we have $\\mu_{i}$ that will differ with each new subject and $\\eta_{ij}$ that will differ with each observation within each subject.\n",
    "\n",
    "What does this mean for both $\\mu_{i}$ and $\\eta_{ij}$? Well, what do we call a variable that changes every time we observe it? A *random variable*. So, both $\\mu_{i}$ and $\\eta_{ij}$ are *random variables*. This means that they *both* have some underlying distribution that they are drawn from. As we know, the $\\eta_{ij}$ are *errors* and thus reflect *deflections* around the expected value. As such, their distribution is the same as it always was \n",
    "\n",
    "$$\n",
    "\\eta_{ij} \\sim \\mathcal{N}\\left(0, \\sigma^{2}_{w}\\right).\n",
    "$$\n",
    "\n",
    "But what about the $\\mu_{i}$? Well, as written above, these are *means* for each subject, so their expected value will not be 0. Instead, it will be whatever the *population grand mean* happens to be. Their variance will then represent the variability of the subject means, which we will call $\\sigma^{2}_{b}$. As such\n",
    "\n",
    "$$\n",
    "\\mu_{i} \\sim \\mathcal{N}\\left(\\mu, \\sigma^{2}_{b}\\right).\n",
    "$$\n",
    "\n",
    "As we know from our discussions last semester, we can always write a linear model as an equation for the mean function with the probabilistic behaviour of the random variable attributable to an error term. So we can write the above as\n",
    "\n",
    "$$\n",
    "\\mu_{i} = \\mu + S_{i}\n",
    "$$\n",
    "\n",
    "with\n",
    "\n",
    "$$\n",
    "S_{i} \\sim \\mathcal{N}(0,\\sigma^{2}_{b})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdda9aa6",
   "metadata": {},
   "source": [
    "\n",
    "## The Complete Multilevel Model\n",
    "So, putting all these pieces together, our full model is now\n",
    "\n",
    "$$\n",
    "\\begin{alignat*}{1}\n",
    "    y_{ij}        &= \\mu_{i} + \\alpha_{j} + \\eta_{ij}  \\\\\n",
    "    \\mu_{i}       &= \\mu + S_{i} \\\\\n",
    "\\end{alignat*}\n",
    "$$\n",
    "\n",
    "with\n",
    "\n",
    "$$\n",
    "\\begin{alignat*}{1}\n",
    "     S_{i}    &\\sim \\mathcal{N}\\left(0,\\sigma^{2}_{b}\\right)   \\\\\n",
    "    \\eta_{ij} &\\sim \\mathcal{N}\\left(0,\\sigma^{2}_{w}\\right) \\\\\n",
    "\\end{alignat*}\n",
    "$$\n",
    "\n",
    "So, these are in fact *two* models that are *linked together*. We have a *hierarchy* of models, or a single model with *multiple levels*. Indeed, from the multilevel perspective, it is typical to label these models like so\n",
    "\n",
    "$$\n",
    "\\begin{alignat*}{2}\n",
    "    y_{ij}        &= \\mu_{i} + \\alpha_{j} + \\eta_{ij} &\\quad\\text{(Level 1)} \\\\\n",
    "    \\mu_{i}       &= \\mu + S_{i}                      &\\quad\\text{(Level 2)} \\\\\n",
    "\\end{alignat*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7204ac",
   "metadata": {},
   "source": [
    "### The Data-generating Process\n",
    "In order to fully conceptualise what the multilevel model is saying, we need to think of it as an explanation of *where* our data come from.\n",
    "\n",
    "So, for a single subject, their mean for a given value of `time` is *unique* to them. But we can decompose this into a *subject-specific* mean and a constant effect of `time`. So each measurement from each subject is composed of three parts\n",
    "\n",
    "1. $\\mu_{i}$ - something unique and specific to individual $i$ that is true across all measurements taken from them\n",
    "2. $\\alpha_{j}$ - something universal about the effect of time-point $j$ that is true irrespective of the individual\n",
    "3. $\\eta_{ij}$ - a random perturbation of measurement $ij$ that captures all the reasons why this is not exactly $\\mu_{i} + \\alpha_{j}$\n",
    "\n",
    "... SO we can think of the expected value *conditional* on a specific subject. For instance, when $i = 1$ we expect\n",
    "\n",
    "$$\n",
    "E(y_{1j}) = \\mu_{1} + \\alpha_{j}.\n",
    "$$\n",
    "\n",
    "So each subject has their own specific mean. However, whenever we consider *all* subjects we have\n",
    "\n",
    "$$\n",
    "E(y_{ij}) = E(\\mu_{i}) + \\alpha_{j} = \\mu + \\alpha_{j}.\n",
    "$$\n",
    "\n",
    "which consists of only those effects that are *universal* across all subjects. Again, this captures the idea that we have many *little* models for each individual subject as well as one *big* model for all subjects. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b096bf3",
   "metadata": {},
   "source": [
    "### Fitting Individual Linear Models in `R`\n",
    "Each time we do this, we will collect the estimates of $\\mu_{i}$ and $\\epsilon_{ij}$, just to demonstrate that these are the elements that truly *do* change with each new subject. We will then show the distribution of these at the end to illustrate that these terms are indeed *random variables*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77ff0f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "level.1 <- lm(score ~ 0 + id + time, data=selfesteem.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67c35ac",
   "metadata": {},
   "source": [
    "Notice that this bears a striking similarity to how we specified the repeated measures ANOVA using `lm()` a couple of weeks ago. We will make this connection more explicit a little later in this lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a560848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = score ~ 0 + id + time, data = selfesteem.long)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-1.3509 -0.5233 -0.0888  0.5304  1.9560 \n",
       "\n",
       "Coefficients:\n",
       "       Estimate Std. Error t value Pr(>|t|)    \n",
       "id1      3.3350     0.6078   5.487 3.28e-05 ***\n",
       "id2      3.1631     0.6078   5.204 5.98e-05 ***\n",
       "id3      3.7253     0.6078   6.129 8.66e-06 ***\n",
       "id4      3.3961     0.6078   5.588 2.65e-05 ***\n",
       "id5      2.3156     0.6078   3.810 0.001283 ** \n",
       "id6      2.5832     0.6078   4.250 0.000482 ***\n",
       "id7      3.2189     0.6078   5.296 4.91e-05 ***\n",
       "id8      3.0261     0.6078   4.979 9.72e-05 ***\n",
       "id9      3.3630     0.6078   5.533 2.97e-05 ***\n",
       "id10     3.2747     0.6078   5.388 4.04e-05 ***\n",
       "timet2   1.7938     0.4298   4.174 0.000570 ***\n",
       "timet3   4.4962     0.4298  10.462 4.44e-09 ***\n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "Residual standard error: 0.961 on 18 degrees of freedom\n",
       "Multiple R-squared:  0.9824,\tAdjusted R-squared:  0.9707 \n",
       "F-statistic: 83.89 on 12 and 18 DF,  p-value: 2.944e-13\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(level.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f02f4d1",
   "metadata": {},
   "source": [
    "So, we now have individual effects unique to each subject, as well as effects of `time` that exist *across* subjects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94bdb244",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu.i    <- coef(level.1)[1:10]\n",
    "level.2 <- lm(mu.i ~ 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0abddd7",
   "metadata": {},
   "source": [
    "Due to the way the model is coded, this is therefore the *group mean* for `time1`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c92ba8",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "name": "r"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
