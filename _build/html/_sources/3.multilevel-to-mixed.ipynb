{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a6b3fd6-1753-45e7-a920-fccf68cbdcac",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# From Multilevel to Mixed-effects\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21408cb",
   "metadata": {},
   "source": [
    "## Why Collapse Our Hierarchy?\n",
    "\n",
    "- The model is always estimated as a single unit, with the levels informing each other\n",
    "- Multilevel implies that we can estimate each level separately, which loses the whole advantage of this framework (this is known as a *summary statistics* approach)\n",
    "- Software is harder to write in a multilevel fashion (though it does exist e.g. MLM, MLwin), whereas a single function call for a single model fits happily inside the usual `R` approach\n",
    "\n",
    "So we can think, very broadly, that the hierarchical perspective is useful *intuitively*, but the mixed-effects perspective is useful *practically*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0daeed9",
   "metadata": {},
   "source": [
    "## From Multilevel to Mixed-effects\n",
    "... So, the key here is recognising that we can collapse the two equations\n",
    "\n",
    "$$\n",
    "\\begin{alignat*}{1}\n",
    "    y_{ij}    &= \\mu_{i} + \\alpha_{j} + \\eta_{ij}  \\\\\n",
    "    \\mu_{i}   &= \\mu + S_{i}                       \\\\\n",
    "\\end{alignat*}\n",
    "$$\n",
    "\n",
    "After all, we can see exactly what $\\mu_{i}$ is equal to. So let us replace $\\mu_{i}$ in the first equation with the equality in the second equation. If we do so, we get\n",
    "\n",
    "$$\n",
    "\\begin{alignat*}{1}\n",
    "    y_{ij} &= (\\mu + S_{i}) + \\alpha_{j} + \\eta_{ij} \\\\\n",
    "           &= \\mu + \\alpha_{j} + S_{i} + \\eta_{ij}\n",
    "\\end{alignat*}\n",
    "$$\n",
    "\n",
    "with\n",
    "\n",
    "$$\n",
    "\\begin{alignat*}{1}\n",
    "    S_{i}     &\\sim \\mathcal{N}\\left(0,\\sigma^{2}_{b}\\right) \\\\\n",
    "    \\eta_{ij} &\\sim \\mathcal{N}\\left(0,\\sigma^{2}_{w}\\right) \\\\\n",
    "\\end{alignat*}\n",
    "$$\n",
    "\n",
    "This is *exactly the partitioned error model we saw last week*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c92ba8",
   "metadata": {},
   "source": [
    "## Mixed-effects Using `lme()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06eb3827",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e520704",
   "metadata": {},
   "outputs": [],
   "source": [
    "library('datarium')\n",
    "library('reshape2')\n",
    "\n",
    "data('selfesteem')\n",
    "\n",
    "# repeats and number of subjects\n",
    "t <- 3\n",
    "n <- dim(selfesteem)[1]\n",
    "\n",
    "# reshape wide -> long\n",
    "selfesteem.long <- melt(selfesteem,            # wide data frame\n",
    "                        id.vars='id',          # what stays fixed?\n",
    "                        variable.name=\"time\",  # name for the new predictor\n",
    "                        value.name=\"score\")    # name for the new outcome\n",
    "\n",
    "selfesteem.long           <- selfesteem.long[order(selfesteem.long$id),] # order by ID\n",
    "rownames(selfesteem.long) <- seq(1,n*t)                                  # fix row names\n",
    "selfesteem.long$id        <- as.factor(selfesteem.long$id)               # convert ID to factor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8f9789",
   "metadata": {},
   "source": [
    "## Mixed-effects Models Applied to Repeated Measurements\n",
    "... So, in fact, applying the model above effectively takes us back to the *repeated measures ANOVA*. This is not a coincidence. The repeated measures ANOVA *is* a very basic multilevel/mixed-effects model. So, it may appear that despite all the discussion above, we have not actually made any progress. In a way, this is *true*. ... This alone reveals a truth about multilevel/mixed-effects models that is not always appreciated: if you have *no* replications per-subject and per-repeated measurements, a multilevel/mixed-effects model will do *no  better* than a repeated measures ANOVA. In fact, it is arguably *worse* because the mixed-effects model has no correction for violations of sphericity. The covariance structure simply is what it is and the inference is based off of this assumption. These correction exist for the repeated measures ANOVA precisely because it has no flexibility in its covariance structure. Because mixed-effects models have much more flexibility, there is no sense of applying a correction for misspecification. If we want a more flexible structure, we just need to specify it. However, because this structure is *implicit*, the data must be able to support it. When the data cannot, we fallback on a simpler structure. So, when mixed-effects and the repeated measures ANOVA converge, the is argument to be made that mixed-effects is actually *less precise* for inference.\n",
    "\n",
    "Now, there *are* advantages to the mixed-effects framework with a compound symmetric covariance structure. For instance, we do not need to manually assign error terms for tests..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "338e194e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear mixed-effects model fit by REML\n",
      "  Data: selfesteem.long \n",
      "       AIC      BIC    logLik\n",
      "  86.99346 93.47264 -38.49673\n",
      "\n",
      "Random effects:\n",
      " Formula: ~1 | id\n",
      "         (Intercept)  Residual\n",
      "StdDev: 2.772358e-05 0.8859851\n",
      "\n",
      "Fixed effects:  score ~ time \n",
      "               Value Std.Error DF   t-value p-value\n",
      "(Intercept) 3.140122 0.2801731 18 11.207793   0e+00\n",
      "timet2      1.793820 0.3962246 18  4.527281   3e-04\n",
      "timet3      4.496220 0.3962246 18 11.347655   0e+00\n",
      " Correlation: \n",
      "       (Intr) timet2\n",
      "timet2 -0.707       \n",
      "timet3 -0.707  0.500\n",
      "\n",
      "Standardized Within-Group Residuals:\n",
      "       Min         Q1        Med         Q3        Max \n",
      "-1.4987927 -0.6279054 -0.0321792  0.4530803  2.4177254 \n",
      "\n",
      "Number of Observations: 30\n",
      "Number of Groups: 10 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Analysis of Deviance Table (Type II tests)\n",
       "\n",
       "Response: score\n",
       "      Chisq Df Pr(>Chisq)    \n",
       "time 130.52  2  < 2.2e-16 ***\n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "library(nlme)\n",
    "library(car)\n",
    "lme.mod <- lme(score ~ time, random= ~ 1|id, data=selfesteem.long)\n",
    "print(summary(lme.mod))\n",
    "\n",
    "Anova(lme.mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1e3be5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "name": "r"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
